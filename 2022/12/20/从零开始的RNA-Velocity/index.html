<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.6.2" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.6.2" type="image/png" sizes="32x32"><meta name="description" content="是什么？怎么来？怎么做？">
<meta property="og:type" content="article">
<meta property="og:title" content="从零开始的RNA Velocity">
<meta property="og:url" content="https://biobrick.github.io/2022/12/20/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84RNA-Velocity/">
<meta property="og:site_name" content="Bio Harbor">
<meta property="og:description" content="是什么？怎么来？怎么做？">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-12-20T11:30:30.000Z">
<meta property="article:modified_time" content="2022-12-20T15:16:56.000Z">
<meta property="article:author" content="Chong Yin">
<meta name="twitter:card" content="summary"><title>从零开始的RNA Velocity | Bio Harbor</title><link ref="canonical" href="https://biobrick.github.io/2022/12/20/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84RNA-Velocity/"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.6.2"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: true,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"复制","copySuccess":"复制成功","copyError":"复制失败"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 6.0.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">首页</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">归档</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">Bio Harbor</div><div class="header-banner-info__subtitle"></div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">从零开始的RNA Velocity</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2022-12-20</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2022-12-20</span></span></div></header><div class="post-body"><p>RNA Velocity目前已经成为比较高级的单细胞动态分析，目前已有的方法，主要是最初的Velocyto和改良的scVelo，引入了metabolite label seq的dynamo，基于多组学的MultiVelo和在空间转录组层面应用的<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://doi.org/10.1101/2021.07.26.453774">SIRV</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>。目前基于RNA Velocity的单细胞动力学分析是最为可靠的单细胞层面的细胞动态分析，基于此还有一些衍生工具，比如CellRank，可以使用RNA Velocity数据推断细胞发育路径（这个其实挺迷惑，毕竟Velocity的信息已经能够很充分地进行细胞发育路径推断了。）</p>
<p>此外，由于真实的Velocity分析的计算开销非常恐怖，因此出现了一些基于纯转录组数据进行推断的工具，这些工具主要有两个方面的作用，一是向量场的推断，也就是全局层面的RNA Velocity，二是动力学推断，也即单个细胞的Velocity Vector的计算和推断。这些工具有VECTOR、scTour和DeepVelo，前者是一个R的脚本工具，后者是一个基于深度学习的python工具，二者从结果上讲，scTour更为出色一些，因为除了向量场推断之外，还顺便做了latent space的学习，可以理解为顺手做了个拟时序。除此之外，诸如PHATE降维，SPRING降维实际上已经有一些细胞向量方向上推断的意思了，只是当时还没有这个概念。</p>
<p>然而RNA Velocity的分析似乎长期处于一个教程不足的状态，原因很多，但最主要的是因为其涉及到多环境切换，如果要完完整整从FASTQ文件做一份RNA Velocity分析，需要涉及linux、python和R，目前来讲可以说是最为全面的分析范式，涉及到单细胞分析的全部方面是，所有数据，各种数据类型和全部分析步骤，如果只是为了得到一个简单的Velocity的结果，似乎有点不划算，因此通常在一开始就要决定好是否做这个分析，否则后期补的话那可以说是非常痛苦。</p>
<p>从各个工具的教程来看，典型的start都是给一个loom文件，然后用各种工具读入，然后就开始进行velocity的计算了，这个loom文件中，稍微知道一点的人就能发现，预处理、降维聚类、细胞注释乃至去批次，全都做好了，直接进行velocity的计算就行，但实际上呢？自己的数据，甚至从公司拿到的数据都不可能直接给一个loom文件，或者给一个loom文件但缺少一些关键信息，总之就是缺这缺那，网上各种教程都喜欢直接用官方给的做好的文件，这种意义不大。</p>
<p>那么，这个loom文件是怎么来的？哪些信息最为重要？这是最关键的两个问题：</p>
<ul>
<li>loom文件从上游的bam文件获得，可以使用3个pipeline：Velocyto，loompy和kallisto+bustool</li>
<li>最关键的信息：就是spliced/unspliced的metric，其余所有信息都是次要的，在其他工具里使用/获取到的</li>
</ul>
<p>因此，这两个方面的信息怎么来？</p>
<p>首先，以10X提供的最为经典的pbmc3k的数据为例子，在10X的官网上可以下载到全部的数据，包括FASRQ，上游的bam文件，下游的10X标准输入文件等，这里从bam开始，因此最麻烦的就是得把这里的bam文件下载下来，如果是完全自己跑上游，那么在10X的outs文件夹里就有这个bam，直接使用即可。此外，由于需要对每一个细胞评估splice的情况，因此还需要barcodes.tsv这个文件，而且需要是filtered_gene_bc_matrices里面的barcodes。</p>
<p>需要特别注意的是，使用velocyto的时候，由于路径都是写死的，因此文件夹组织形式和文件名都是有特殊要求的，对于单个project，应当按照下面的文件夹组织，注意如果不会改动源码的话，连文件的名字都要是一样的：</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">./pbmc3k</span><br><span class="line">├── outs</span><br><span class="line">│   ├── cellsorted_possorted_genome_bam.bam</span><br><span class="line">│   ├── filtered_gene_bc_matrices</span><br><span class="line">│   │   └── hg19</span><br><span class="line">│   │       ├── barcodes.tsv</span><br><span class="line">│   │       ├── genes.tsv</span><br><span class="line">│   │       └── matrix.mtx</span><br><span class="line">│   ├── possorted_genome_bam.bam</span><br><span class="line">│   ├── possorted_genome_bam_index.bam.bai</span><br><span class="line">│   └── raw_gene_bc_matrices</span><br><span class="line">│       └── hg19</span><br><span class="line">│           ├── barcodes.tsv</span><br><span class="line">│           ├── genes.tsv</span><br><span class="line">│           └── matrix.mtx</span><br><span class="line">├── pbmc3k_filtered_gene_bc_matrices.tar.gz</span><br><span class="line">├── pbmc3k_raw_gene_bc_matrices.tar.gz</span><br><span class="line">└── velocyto</span><br><span class="line">    └── pbmc3k.loom</span><br></pre></td></tr></table></div></figure>
<p>如果有多个项目，则每一个都要按照这个组织形式，存放在不同的projectname的文件夹里，然后才能使用，如果是smart-seq或者drop-seq的数据，则同样需要bam和类似的组织形式，只是10X用的最多罢了。</p>
<p>这里能看到有个velocyto文件夹，这个里面的pbmc3k.loom就是最后输出的结果了。最开始是没有这个文件夹的。</p>
<p>除了单细胞的数据，由于这里需要切分RNA的splice情况，因此需要基因组的注释文件，其一是在做上游的时候，由10X官方提供的reference里的gene/gene.gtf，这个文件也可以从ensembl网站自己下载，只是但凡跑了上游则必然存在这个文件，容易获得。</p>
<p>第二个注释文件则是masked sequence的gtf注释文件，这个文件可以从GENECODE、ensembl网站获取，但最方便的则是从UCSC Browser中获取，从Table Browser中进行获取下载，需要注意选择好物种、基因组版本、mask sequence选项，输入文件名并使用gzip下载，然后解压就能获得这个文件了。</p>
<p>然后使用velocyto就能获得这个上游的loom文件了。velocyto的安装也有点坑爹，mac和windows上安装非常麻烦，千万别用pip安装，涉及到编译，由于目前的0.17.7版本是19年上传的，如果编译系统太新了还没法编译，非常烦。直接使用github上的源码安装就行了。</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#依赖包安装，建议用conda或者mamba安装</span></span><br><span class="line">conda install numpy scipy cython numba matplotlib scikit-learn h5py click</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/velocyto-team/velocyto.py.git</span><br><span class="line"><span class="built_in">cd</span> velocyto.py</span><br><span class="line">pip install -e .  <span class="comment"># note the trailing dot</span></span><br></pre></td></tr></table></div></figure>
<p>这里只要没有缺依赖库，基本都能装上，连windows都装得上去，然后激活对应的conda环境就能直接使用velocyto了。</p>
<p>实际上，在clone下来velocyto.py后，进入/velocyto.py/velocyto/commands/ 里面就能看到使用的的命令了，如果想改动上游读取数据的方式，在对应的命令里就能进行改动了，比如希望使用全部的raw barcodes而不是filtered之后的barcodes，在run10x.py里改动对应的文件夹名字就好了，或者笨一点的办法是把文件夹的名字改了，只要自己记得就行了。</p>
<p>然后就能使用velocyto命令，生成这里的loom文件了：</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rmsk_gtf=<span class="variable">$YOUR_REF_DIR</span>/hg38_repeat_rmsk.gtf</span><br><span class="line">cellranger_outDir=pbmc3k</span><br><span class="line">cellranger_gtf=<span class="variable">$YOUR_REF_DIR</span>/refdata-gex-GRCh38-2020-A/genes/genes.gtf</span><br><span class="line"></span><br><span class="line">nohup velocyto run10x -m <span class="variable">$rmsk_gtf</span>  <span class="variable">$cellranger_outDir</span> <span class="variable">$cellranger_gtf</span> &amp;</span><br></pre></td></tr></table></div></figure>
<p>然后等着就行了…..个人的渣电脑跑了大概4小时，bam数据15.6G，最后输出一个20+MB的loom…….这一步极其消耗时间，但是一个多线程的步骤，因此建议使用集群运行，大大节省时间空间。</p>
<p>有时候上游的bam没排序或者忘了，则需要手动先排序：</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> <span class="variable">$cellranger_outDir</span>/out </span><br><span class="line">nohup samtools sort -@ 10  -t CB -O BAM -o cellsorted_possorted_genome_bam.bam possorted_genome_bam.bam &amp;</span><br></pre></td></tr></table></div></figure>
<p>sort之后再进行运行即可，但通常只要samtools安装好了是不需要手动做sort这一步的。</p>
<p>多个样品的话，需要对每一个样品进行同样的操作，可以写bash的循环先手动sort：</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ls  */outs/possorted_genome_bam.bam|<span class="keyword">while</span> <span class="built_in">read</span> id;<span class="keyword">do</span>  new=<span class="variable">$&#123;id/possorted_genome_bam.bam/cellsorted_possorted_genome_bam.bam&#125;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$new</span> </span><br><span class="line">nohup samtools sort -@ 4  -t CB -O BAM -o <span class="variable">$new</span>   <span class="variable">$id</span>  &amp; </span><br><span class="line"> <span class="keyword">done</span></span><br></pre></td></tr></table></div></figure>
<p>再批量跑velocyto即可,然后每个project都会有一个velocyto文件夹，里面放着对应的loom文件</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ls -d *-*|<span class="keyword">while</span> <span class="built_in">read</span> cellranger_outDir;<span class="keyword">do</span> </span><br><span class="line">nohup velocyto run10x -m <span class="variable">$rmsk_gtf</span>  <span class="variable">$cellranger_outDir</span> <span class="variable">$cellranger_gtf</span> &amp; </span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></div></figure>
<p>如果使用kallisto+bustools，则相对命令上简单一些，这个pipeline支持直接从上游生成loom文件：</p>
<figure class="highlight bash"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kb ref -i index.idx -g t2g.txt -f1 cdna.fa -f2 intron.fa -c1 cdna_t2c.txt -c2 intron_t2c.txt --workflow lamanno -n 4 \</span><br><span class="line">fasta.fa \</span><br><span class="line">gtf.gtf</span><br><span class="line"></span><br><span class="line">kb count -i transcriptome.idx -g t2g.txt -x 10xv2 --workflow lamanno --loom -c1 cdna_t2c.txt -c2 intron_t2c.txt read_1.fastq.gz read_2.fastq.gz  </span><br></pre></td></tr></table></div></figure>
<p>运行完kb count就会直接出来loom，只要加了—loom参数即可。</p>
<p>这时候，已经距离官方的示例文件SCG71.loom很近了，下游可以跑了。由于velocyto是最原始的方法，结果上不是很稳定，因此现在通常只用它来获取输入，下游采用scVelo或者dynamo进行分析。</p>
<p>scVelo直接读这里生成的loom即可，如果有多个loom则挨个读进去，然后使用scv.utils.merge(adata, ldata……)merge为一个anndata即可，这里只有一个loom，因此暂不需要merge，merge之后的流程和单个文件流程完全一致。</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scvelo <span class="keyword">as</span> scv</span><br><span class="line"><span class="keyword">import</span> scanpy <span class="keyword">as</span> sc</span><br><span class="line"></span><br><span class="line">scv.logging.print_version()</span><br><span class="line">scv.settings.verbosity = <span class="number">3</span>  <span class="comment"># show errors(0), warnings(1), info(2), hints(3)</span></span><br><span class="line">scv.settings.set_figure_params(<span class="string">&#x27;scvelo&#x27;</span>)  <span class="comment"># for beautified visualization</span></span><br><span class="line"></span><br><span class="line">loomf = <span class="string">&#x27;./pbmc3k/velocyto/pbmc3k.loom&#x27;</span></span><br><span class="line">adata = scv.read(loomf, cache=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">adata</span><br><span class="line">adata.var_names_make_unique</span><br></pre></td></tr></table></div></figure>
<p>这里如果熟悉scanpy的会发现，adata中只有两个layer，什么X_umap，PCA降维所有的信息一概没有，因为我们读入的，的确只是一个原始的loom文件，里面的确不包含任何降维聚类注释等信息，因此，这里有两种办法，其一是在进行velocity之前，使用scanpy的流程，把降维聚类先做了，至少要获得PCA、umap/tsne和cell cluster信息，细胞是否进行注释则并不需要，但通常都习惯于直接注释，再继续用scvelo读入即可无缝继续分析，这时候这个loom文件就跟官方提供的SCG71.loom一致，包含了所有的信息，直接开跑velocity，不会有任何障碍，个人推荐采用这个操作，因为这样无论是筛细胞还是跑降维聚类，都是一致的。</p>
<p>第二种则是使用外部工具，比如seurat处理之后，提取关键信息后传入，我们需要提取的信息主要有细胞的barcode，因为Seurat可能对细胞进行了筛选，而且本身二者细胞数就可能是不一致的；第二则是umap的坐标，第三则是cell的annotation，或者其他任何的meta信息。但这样有代价，非常的麻烦，由于python生态对于barcode的处理不太一样，因此需要手动转换掉全部的barcode，并且进行匹配，然后再将meta信息和embedding信息读入后传入anndata，其实还挺麻烦的，当然也可以直接将loom读入R中，针对splice矩阵进行正常的降维聚类分析，然后使用sceasy再将seuratobject转为anndata…..这就有点迷惑操作了，直接用scanpy做不就好了。</p>
<figure class="highlight r"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">write.csv(Cells(seurat_object), file = <span class="string">&quot;cellID_obs.csv&quot;</span>, row.names = <span class="literal">FALSE</span>)</span><br><span class="line">write.csv(Embeddings(seurat_object, reduction = <span class="string">&quot;umap&quot;</span>), file = <span class="string">&quot;cell_embeddings.csv&quot;</span>)</span><br><span class="line">write.csv(seurat_object@meta.data$seurat_clusters, file = <span class="string">&quot;clusters.csv&quot;</span>)</span><br></pre></td></tr></table></div></figure>
<p> 然后就得在py里操作了，如果这里涉及到多个样本，通常会在barcode前面加诸如sample1_, sample2_，这样的前缀用来切分所有的细胞文件，anndata里需要单独映射</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> anndata</span><br><span class="line"><span class="keyword">import</span> scvelo <span class="keyword">as</span> scv</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> plt</span><br><span class="line">%load_ext rpy2.ipython</span><br><span class="line"></span><br><span class="line">sample_one = anndata.read_loom(<span class="string">&quot;sample_one.loom&quot;</span>)</span><br><span class="line">.... </span><br><span class="line">sample_n = anndata.read_loom(<span class="string">&quot;sample_n.loom&quot;</span>)</span><br><span class="line"></span><br><span class="line">sample_obs = pd.read_csv(<span class="string">&quot;cellID_obs.csv&quot;</span>)</span><br><span class="line">umap_cord = pd.read_csv(<span class="string">&quot;cell_embeddings.csv&quot;</span>)</span><br><span class="line">cell_clusters = pd.read_csv(<span class="string">&quot;clusters_obs.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">cellID_obs_sample_one = cellID_obs[cellID_obs_sample_one[<span class="number">0</span>].<span class="built_in">str</span>.contains(<span class="string">&quot;sample1_&quot;</span>)]</span><br><span class="line">cellID_obs_sample_two = cellID_obs[cellID_obs_sample_two[<span class="number">0</span>].<span class="built_in">str</span>.contains(<span class="string">&quot;sample2_&quot;</span>)]</span><br><span class="line">...</span><br><span class="line">cellID_obs_sample_n = cellID_obs[cellID_obs_sample_two[<span class="number">0</span>].<span class="built_in">str</span>.contains(<span class="string">&quot;samplen_&quot;</span>)]</span><br><span class="line"></span><br><span class="line">sample_one = sample_one[np.isin(sample_one.obs.index, cellID_obs_sample_one)]</span><br><span class="line">sample_two = sample_two[np.isin(sample_two.obs.index, cellID_obs_sample_two)]</span><br><span class="line">...</span><br><span class="line">sample_n = sample_n[np.isin(sample_n.obs.index, cellID_obs_sample_n)]</span><br><span class="line"></span><br><span class="line">sample_one = sample_one.concatenate(sample_two, sample_three, sample_four,...)</span><br><span class="line">umap = pd.read_csv(<span class="string">&quot;umap.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">sample_one_index = pd.DataFrame(sample_one.obs.index)</span><br><span class="line">sample_one_index = sample_one_index.rename(columns = &#123;<span class="number">0</span>:<span class="string">&#x27;Cell ID&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">umap = umap.rename(columns = &#123;<span class="string">&#x27;Unnamed: 0&#x27;</span>:<span class="string">&#x27;Cell ID&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">umap_ordered = sample_one_index.merge(umap, on = <span class="string">&quot;Cell ID&quot;</span>)</span><br><span class="line"></span><br><span class="line">umap_ordered = umap_ordered.iloc[:,<span class="number">1</span>:]</span><br><span class="line">sample_one.obsm[<span class="string">&#x27;X_umap&#x27;</span>] = umap_ordered.values</span><br><span class="line"></span><br><span class="line">sample_one.uns[<span class="string">&#x27;Cluster_colors&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#继续velocity，本质上核心就是一个个做好barcode的映射在连接成同一个anndata</span></span><br><span class="line">scv.pp.filter_and_normalize(sample_one)</span><br><span class="line">scv.pp.moments(sample_one)</span><br><span class="line">scv.tl.velocity(sample_one, mode = <span class="string">&quot;stochastic&quot;</span>)</span><br><span class="line">scv.tl.velocity_graph(sample_one)</span><br><span class="line">scv.pl.velocity_embedding(sample_one, basis = <span class="string">&#x27;umap&#x27;</span>)</span><br><span class="line"></span><br><span class="line">color = sample_one.uns[<span class="string">&#x27;Cluster_colors&#x27;</span>]</span><br></pre></td></tr></table></div></figure>
<p>当然，现在还有取巧的办法，那就是使用SCP或者seurat-wrapper等工具，直接RunSCVELO完事…..纯原生R环境，无需担心做映射…..可谓分析里的豪杰…..就是需要有一定的在R中构建py环境的小经验。</p>
<figure class="highlight r"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pancreas_sub &lt;- RunSCVELO(</span><br><span class="line">  srt = pancreas_sub, group_by = <span class="string">&quot;SubCellType&quot;</span>,</span><br><span class="line">  linear_reduction = <span class="string">&quot;PCA&quot;</span>, nonlinear_reduction = <span class="string">&quot;UMAP&quot;</span>, return_seurat = <span class="literal">TRUE</span></span><br><span class="line">)</span><br><span class="line">VelocityPlot(srt = pancreas_sub, reduction = <span class="string">&quot;UMAP&quot;</span>, group_by = <span class="string">&quot;SubCellType&quot;</span>)</span><br><span class="line">VelocityPlot(srt = pancreas_sub, reduction = <span class="string">&quot;UMAP&quot;</span>, plot_type = <span class="string">&quot;stream&quot;</span>)</span><br></pre></td></tr></table></div></figure>
<p>我只能说真的np……</p>
<p>目前看来RNA Velocity的分析，基本上就是cellranger+Velocyto+scanpy/Seurat+scVelo/dynamo/Deepvelo流程，或者Kallisto+Bustools+scanpy/Seurat+scVelo/dynamo/Deepvelo流程，基本已经固定了，这里强烈推荐全python流程，因为不需要匹配来匹配去，环境更加统一，分析完这一步后，再迁移到R环境画图都行。</p>
<p>要学的还有很多，下一步得继续学习多组学的分析了，特别是表观组学的分析，又是一个漫长的旅程。</p>
</div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ 本文结束，感谢您的阅读 ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">本文作者: </span><span class="copyright-author__value"><a href="https://biobrick.github.io">Chong Yin</a></span></div><div class="copyright-link"><span class="copyright-link__name">本文链接: </span><span class="copyright-link__value"><a href="https://biobrick.github.io/2022/12/20/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84RNA-Velocity/">https://biobrick.github.io/2022/12/20/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84RNA-Velocity/</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">版权声明: </span><span class="copyright-notice__value">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> 许可协议。转载请注明出处！</span></div></div><div class="post-reward reward"><div class="reward-button">请我喝杯咖啡~</div><div class="reward-qrcode"><span class="reward-qrcode-alipay"><img class="reward-qrcode-alipay__img" src="/images/alipay.png"><div class="reward-qrcode-alipay__text">支付宝打赏</div></span><span class="reward-qrcode-wechat"><img class="reward-qrcode-wechat__img" src="/images/wechatpay.png"><div class="reward-qrcode-wechat__text">微信打赏</div></span></div></div><nav class="post-paginator paginator"><div class="paginator-next"><a class="paginator-next__link" href="/2022/12/02/%E5%BF%AB%E9%80%9F%E5%88%9B%E5%BB%BA%E4%B8%B4%E5%BA%8A%E5%9F%BA%E7%BA%BF%E8%A1%A8/"><span class="paginator-prev__text">快速创建临床基线表</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">文章目录</span><span class="sidebar-nav-ov">站点概览</span></div><section class="sidebar-toc"></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-social"><a class="sidebar-ov-social-item" href="https://github.com/BIOBRICK/" target="_blank" rel="noopener" data-popover="Github" data-popover-pos="up"><span class="sidebar-ov-social-item__icon"><i class="fab fa-github"></i></span></a><a class="sidebar-ov-social-item" href="386396663" target="_blank" rel="noopener" data-popover="QQ" data-popover-pos="up"><span class="sidebar-ov-social-item__icon"><i class="fab fa-qq"></i></span></a></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">21</div><div class="sidebar-ov-state-item__name">归档</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="知识共享许可协议" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">你已阅读了 </span><span class="sidebar-reading-info__num">0</span><span class="sidebar-reading-info__perc">%</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2023</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>Chong Yin</span></div><div><span>主题 - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.6.2</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="/js/utils.js?v=2.6.2"></script><script src="/js/stun-boot.js?v=2.6.2"></script><script src="/js/scroll.js?v=2.6.2"></script><script src="/js/header.js?v=2.6.2"></script><script src="/js/sidebar.js?v=2.6.2"></script></body></html>